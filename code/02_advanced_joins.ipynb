{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d9b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3dbc0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nConvert the 'time_hour' column in flights_df and weather_df to datetime64[ns] type, as it was 'object'.\\nThis was necessary because a merge on date/time types was not possible otherwise.\\n\\nThe dtype for flights_df was datetime64[ns], while for weather_df it was datetime64[ns, UTC]. Removed the UTC timezone.\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_directory = Path.cwd()                            # directory of the file - folder \"code\"\n",
    "data_directory = basic_directory.parent / \"data\"        # go one level up and choose folder \"data\"\n",
    "\n",
    "# It's a common convention to add a _df suffix to a variable name to indicate it's a DataFrame.\n",
    "flights_df  = pd.read_csv(data_directory / \"flights.csv\")\n",
    "airlines_df = pd.read_csv(data_directory / \"airlines.csv\")\n",
    "airports_df = pd.read_csv(data_directory / \"airports.csv\")\n",
    "planes_df   = pd.read_csv(data_directory / \"planes.csv\")\n",
    "weather_df  = pd.read_csv(data_directory / \"weather.csv\")\n",
    "\n",
    "# Convert to datetime\n",
    "flights_df['time_hour'] = pd.to_datetime(flights_df['time_hour'])\n",
    "weather_df['time_hour'] = pd.to_datetime(weather_df['time_hour'])\n",
    "\n",
    "# Remove timezone\n",
    "weather_df['time_hour'] = weather_df['time_hour'].dt.tz_localize(None)\n",
    "\n",
    "'''\n",
    "Convert the 'time_hour' column in flights_df and weather_df to datetime64[ns] type, as it was 'object'.\n",
    "This was necessary because a merge on date/time types was not possible otherwise.\n",
    "\n",
    "The dtype for flights_df was datetime64[ns], while for weather_df it was datetime64[ns, UTC]. Removed the UTC timezone.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f1e7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tailnum carrier                         name  flight_count\n",
      "616   N335AA      AA       American Airlines Inc.            18\n",
      "1599  N711MQ      MQ                    Envoy Air            18\n",
      "315   N183JB      B6              JetBlue Airways            17\n",
      "629   N339AA      AA       American Airlines Inc.            17\n",
      "1420  N632JB      B6              JetBlue Airways            17\n",
      "...      ...     ...                          ...           ...\n",
      "2257  N960AT      FL  AirTran Airways Corporation             1\n",
      "2259  N961AT      FL  AirTran Airways Corporation             1\n",
      "937   N426AA      AA       American Airlines Inc.             1\n",
      "2264  N963AT      FL  AirTran Airways Corporation             1\n",
      "2280  N969AT      FL  AirTran Airways Corporation             1\n",
      "\n",
      "[2328 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find the aircraft with the most flights and its airline\n",
    "\n",
    "highest_no = planes_df.merge(flights_df, on='tailnum', how='left')\n",
    "highest_no = highest_no.merge(airlines_df, on='carrier', how='left')\n",
    "\n",
    "result = (\n",
    "    highest_no\n",
    "    .groupby(['tailnum', 'carrier', 'name'], dropna=False)\n",
    "    .size()                                       # Equivalent to COUNT(*)\n",
    "    .reset_index(name='flight_count')             # Rename the resulting column\n",
    "    .sort_values('flight_count', ascending=False) # ORDER BY flight_count DESC\n",
    ")\n",
    "print(result)\n",
    "# The aircraft with the most flights are N711MQ and N335AA, with 18 flights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23b42c0",
   "metadata": {},
   "source": [
    "So, in this query in SQL NaN values are INCLUDED, so even if aircraft has never flown, it'll be in our result.\n",
    "In pandas groupby NaN values ARE DROPED by default, so there were 998 less observations (these aircrafts that has never flown).\n",
    "\n",
    "1. If I want (in pandas) to include all values - add dropna=False in groupby()\n",
    "2. If I want (SQL) to drop NaN (NULL in SQL) values in SQL - just use INNER JOIN (in THIS case its useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec2d230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tailnum  carriers_count\n",
      "414   N228PQ               2\n",
      "423   N232PQ               2\n",
      "2770  N977AT               2\n",
      "2789  N990AT               2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSELECT tailnum, COUNT(DISTINCT carrier) as carriers_count\\nFROM flights\\nGROUP BY tailnum\\nHAVING COUNT(DISTINCT carrier) > 1\\nORDER BY carriers_count DESC;\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before splitting into carriers, there were 3322 lines; after splitting, there were 3326 lines.\n",
    "# The query above shows which aircraft and how many flew for more than one airline\n",
    "\n",
    "result = (\n",
    "    flights_df\n",
    "    .groupby('tailnum')['carrier']\n",
    "    .nunique()                                    # Equivalent to COUNT(DISTINCT carrier)\n",
    "    .reset_index(name='carriers_count')           # Move 'tailnum' from index to a column\n",
    "    .query(\"carriers_count > 1\")                  # Equivalent to HAVING\n",
    "    .sort_values('carriers_count', ascending=False)\n",
    ")\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65366923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     carrier                    name  month  minute  dep_time\n",
      "525       AA  American Airlines Inc.      6      15    1311.0\n",
      "530       AA  American Airlines Inc.      6      30    1148.0\n",
      "533       AA  American Airlines Inc.      6       0     656.0\n",
      "550       AA  American Airlines Inc.      6       0    1958.0\n",
      "572       AA  American Airlines Inc.      6      15    1134.0\n",
      "...      ...                     ...    ...     ...       ...\n",
      "8796      UA   United Air Lines Inc.      6      40     900.0\n",
      "8817      UA   United Air Lines Inc.      6      29       NaN\n",
      "8818      UA   United Air Lines Inc.      6      47    1145.0\n",
      "8826      UA   United Air Lines Inc.      6      10     605.0\n",
      "8828      UA   United Air Lines Inc.      6      12    1008.0\n",
      "\n",
      "[236 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nresult = full_join.query(\"carrier in [\\'UA\\', \\'AA\\'] and month == 6\")[[\\'carrier\\', \\'name\\', \\'month\\', \\'minute\\', \\'dep_time\\']]\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple query for FULL JOIN\n",
    "\n",
    "full_join = airlines_df.merge(flights_df, on='carrier', how='outer')\n",
    "\n",
    "result = (\n",
    "    full_join\n",
    "    .loc[full_join['carrier'].isin(['UA', 'AA']) & (full_join['month']==6),     # row filter\n",
    "    ['carrier', 'name', 'month', 'minute', 'dep_time']]\n",
    ")\n",
    "print(result)\n",
    "# .isin checks if a value in a column is present in the provided list.\n",
    "\n",
    "# equivalent with .query()\n",
    "'''\n",
    "result = full_join.query(\"carrier in ['UA', 'AA'] and month == 6\")[['carrier', 'name', 'month', 'minute', 'dep_time']]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cd1bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dest origin                    name\n",
      "72      TPA    JFK  Hawaiian Airlines Inc.\n",
      "88      BOS    JFK  Hawaiian Airlines Inc.\n",
      "104     SFO    JFK  Hawaiian Airlines Inc.\n",
      "120     IAD    JFK  Hawaiian Airlines Inc.\n",
      "168     CHS    JFK  Hawaiian Airlines Inc.\n",
      "...     ...    ...                     ...\n",
      "159880  IND    JFK  Hawaiian Airlines Inc.\n",
      "159896  SAN    JFK  Hawaiian Airlines Inc.\n",
      "159912  SEA    JFK  Hawaiian Airlines Inc.\n",
      "159928  LAX    JFK  Hawaiian Airlines Inc.\n",
      "159960  PBI    JFK  Hawaiian Airlines Inc.\n",
      "\n",
      "[3276 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nOriginal SQL: A simple query for CROSS JOIN\\n\\nSELECT fl.dest, fl.origin, al.name\\nFROM flights AS fl\\nCROSS JOIN airlines AS al\\nWHERE fl.origin IN ('JFK') AND al.carrier IN ('HA');\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple query for CROSS JOIN\n",
    "\n",
    "cross_join = flights_df.merge(airlines_df, how='cross', suffixes=(\"_flights\", \"_airlines\"))\n",
    "\n",
    "result = (\n",
    "    cross_join\n",
    "    .loc[(cross_join['origin']=='JFK') & (cross_join['carrier_airlines']=='HA'),\n",
    "         ['dest', 'origin', 'name']]\n",
    ")\n",
    "print(result)\n",
    "\n",
    "\n",
    "# Each row from flights_df is joined with every row from airlines_df.\n",
    "# If carrier_flights == \"HA\", it would ONLY select rows where the carrier in FLIGHTS_DF is Hawaiian Airlines.\n",
    "# If carrier_airlines == \"HA\", it selects ALL flights but only keeps rows where the AIRLINES_DF lookup points to HAWAIIAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8bf0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         day_fl1  day_fl2  month\n",
      "1             27        9      6\n",
      "2             27        4      6\n",
      "3             27       17      6\n",
      "4             27       14      6\n",
      "5             27       24      6\n",
      "...          ...      ...    ...\n",
      "8359012       18        4     11\n",
      "8359013       18        4     11\n",
      "8359014       18       19     11\n",
      "8359015       18        5     11\n",
      "8359016       18       16     11\n",
      "\n",
      "[8073012 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nOriginal SQL: SELF JOIN (comparing a column with different values within the same table).\\n\\n-- This query compares days within the same month from the flights table.\\nSELECT fl1.day AS day1, fl2.day AS day2, fl1.month\\nFROM flights AS fl1\\nINNER JOIN flights AS fl2\\nON fl1.month=fl2.month\\nAND fl1.day<>fl2.day\\nLIMIT 40;\\n/* The query logic (simplified):\\nIt first takes \"January 1st with all other days in January\",\\nthen \"January 2nd with all other days\", and so on.\\n*/;\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple query for SELF JOIN\n",
    "\n",
    "self_join = flights_df.merge(flights_df, on='month', suffixes=(\"_fl1\", \"_fl2\"))\n",
    "\n",
    "result = (\n",
    "    self_join\n",
    "    .query(\"day_fl1 != day_fl2\") # Equivalent to WHERE\n",
    "    [[\"day_fl1\", \"day_fl2\", \"month\"]]\n",
    ")\n",
    "print(result)\n",
    "\n",
    "# This query compares days within the same month from the flights table\n",
    "\n",
    "# The query logic (simplified):\n",
    "# It first takes \"January 1st with all other days in January\",\n",
    "# then \"January 2nd with all other days\", and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0717b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       flight_fl1  flight_fl2 origin_fl1 origin_fl2 dest  sched_arr_time_fl1  \\\n",
      "1051          127         695        EWR        JFK  MCO                1350   \n",
      "1313          409         219        EWR        JFK  CLT                1023   \n",
      "1767         4440           8        EWR        JFK  BUF                1556   \n",
      "3419          763         399        JFK        JFK  LAX                1011   \n",
      "5122          745        3676        EWR        LGA  CLT                 826   \n",
      "4958         1047        2357        EWR        JFK  SAN                2158   \n",
      "11314         177        1495        JFK        EWR  SFO                2210   \n",
      "2701          935        2247        EWR        LGA  ATL                1631   \n",
      "12652        5207        2095        LGA        EWR  CLT                1507   \n",
      "12405         348         781        LGA        LGA  ATL                1535   \n",
      "11539         501         371        JFK        LGA  FLL                 854   \n",
      "4583          245         561        EWR        LGA  DEN                1024   \n",
      "16775        4478        4984        LGA        EWR  DTW                1110   \n",
      "8373         3374        3443        JFK        JFK  RDU                2145   \n",
      "5054         2171        3792        LGA        JFK  DCA                1213   \n",
      "8839           95         413        JFK        JFK  LAX                2018   \n",
      "16030           3         703        JFK        JFK  LAX                1510   \n",
      "11163         269        4610        JFK        LGA  ATL                1108   \n",
      "13244         857        1626        JFK        EWR  SAN                1151   \n",
      "15012        1480         397        EWR        JFK  SFO                1152   \n",
      "5945          329        1199        LGA        EWR  ORD                1440   \n",
      "15265        1042        1989        JFK        EWR  CLT                 808   \n",
      "8078         2132        3452        LGA        JFK  BOS                1608   \n",
      "2766         1769         779        JFK        LGA  MIA                1835   \n",
      "7371         4171        5259        EWR        LGA  MSN                1534   \n",
      "11817        1262         303        EWR        LGA  ORD                 810   \n",
      "10834        1499        2042        LGA        EWR  ATL                1939   \n",
      "12398        1331         161        JFK        EWR  DEN                1850   \n",
      "14569        1433        4471        LGA        EWR  CLT                 832   \n",
      "13116        3341        2126        JFK        LGA  BOS                1315   \n",
      "15298        3523        1105        JFK        JFK  ORD                1749   \n",
      "4249          407         161        JFK        EWR  LAX                1220   \n",
      "15821         504        3962        EWR        LGA  MDW                1935   \n",
      "16922         371        3744        LGA        EWR  ORD                2225   \n",
      "\n",
      "       sched_arr_time_fl2  difference  \n",
      "1051                 1349           1  \n",
      "1313                 1022           1  \n",
      "1767                 1555           1  \n",
      "3419                 1010           1  \n",
      "5122                  825           1  \n",
      "4958                 2157           1  \n",
      "11314                2209           1  \n",
      "2701                 1629           2  \n",
      "12652                1505           2  \n",
      "12405                1533           2  \n",
      "11539                 852           2  \n",
      "4583                 1022           2  \n",
      "16775                1108           2  \n",
      "8373                 2142           3  \n",
      "5054                 1210           3  \n",
      "8839                 2015           3  \n",
      "16030                1507           3  \n",
      "11163                1105           3  \n",
      "13244                1147           4  \n",
      "15012                1148           4  \n",
      "5945                 1436           4  \n",
      "15265                 804           4  \n",
      "8078                 1604           4  \n",
      "2766                 1830           5  \n",
      "7371                 1529           5  \n",
      "11817                 805           5  \n",
      "10834                1934           5  \n",
      "12398                1845           5  \n",
      "14569                 827           5  \n",
      "13116                1310           5  \n",
      "15298                1744           5  \n",
      "4249                 1215           5  \n",
      "15821                1930           5  \n",
      "16922                2220           5  \n",
      "(34, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Equivalent without .assign:\\n\\nresult = (\\n    same_time\\n    .loc[\\n         (same_time[\"sched_arr_time_fl1\"] > same_time[\"sched_arr_time_fl2\"]) &\\n         ((same_time[\"sched_arr_time_fl1\"] - same_time[\"sched_arr_time_fl2\"]) <= 3),\\n         [\"flight_fl1\", \"flight_fl2\", \"origin_fl1\", \"origin_fl2\", \"dest\", \"sched_arr_time_fl1\", \"sched_arr_time_fl2\"]\\n    ]\\n)\\nresult[\\'difference\\'] = result[\\'sched_arr_time_fl1\\'] - result[\\'sched_arr_time_fl2\\']\\nresult = result.sort_values(\\'difference\\', ascending=True)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This SQL query finds pairs of flights with the same destination (dest)\n",
    "# that arrive on the same day with an interval of no more than 5 minutes\n",
    "\n",
    "same_time = flights_df.merge(flights_df, on=[\"dest\", \"day\", \"month\"], suffixes=(\"_fl1\", \"_fl2\"))\n",
    "\n",
    "result = (\n",
    "    same_time\n",
    "    .loc[\n",
    "         (same_time[\"sched_arr_time_fl1\"] > same_time[\"sched_arr_time_fl2\"]) &\n",
    "         ((same_time[\"sched_arr_time_fl1\"] - same_time[\"sched_arr_time_fl2\"]) <= 5),\n",
    "         [\"flight_fl1\", \"flight_fl2\", \"origin_fl1\", \"origin_fl2\", \"dest\", \"sched_arr_time_fl1\", \"sched_arr_time_fl2\"]\n",
    "    ]\n",
    "    .assign(difference=lambda df:    df[\"sched_arr_time_fl1\"] - df[\"sched_arr_time_fl2\"])  # Creating new column \"difference\" with value equral to diff. between \"...fl1\" and \"...fl2\"\n",
    "    .sort_values(\"difference\", ascending=True )\n",
    ")\n",
    "print(result)\n",
    "print(result.shape)\n",
    "\n",
    "'''\n",
    "# Equivalent without .assign:\n",
    "\n",
    "result = (\n",
    "    same_time\n",
    "    .loc[\n",
    "         (same_time[\"sched_arr_time_fl1\"] > same_time[\"sched_arr_time_fl2\"]) &\n",
    "         ((same_time[\"sched_arr_time_fl1\"] - same_time[\"sched_arr_time_fl2\"]) <= 3),\n",
    "         [\"flight_fl1\", \"flight_fl2\", \"origin_fl1\", \"origin_fl2\", \"dest\", \"sched_arr_time_fl1\", \"sched_arr_time_fl2\"]\n",
    "    ]\n",
    ")\n",
    "result['difference'] = result['sched_arr_time_fl1'] - result['sched_arr_time_fl2']\n",
    "result = result.sort_values('difference', ascending=True)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
